{
  "dashboard": {
    "id": null,
    "title": "CarlaRL Policy Service - Production Monitoring",
    "tags": ["carla-rl", "ml-serving", "production"],
    "style": "dark",
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Service Overview",
        "type": "stat",
        "targets": [
          {
            "expr": "carla_rl_model_loaded",
            "legendFormat": "Model Loaded"
          },
          {
            "expr": "carla_rl_model_warmed_up",
            "legendFormat": "Model Warmed Up"
          },
          {
            "expr": "carla_rl_service_uptime_seconds",
            "legendFormat": "Uptime (hours)",
            "format": "s"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "thresholds"},
            "thresholds": {
              "steps": [
                {"color": "red", "value": 0},
                {"color": "green", "value": 1}
              ]
            }
          }
        }
      },
      {
        "id": 2,
        "title": "Inference Latency (P50, P95, P99)",
        "type": "timeseries",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(carla_rl_inference_duration_seconds_bucket[5m]))",
            "legendFormat": "P50"
          },
          {
            "expr": "histogram_quantile(0.95, rate(carla_rl_inference_duration_seconds_bucket[5m]))",
            "legendFormat": "P95"
          },
          {
            "expr": "histogram_quantile(0.99, rate(carla_rl_inference_duration_seconds_bucket[5m]))",
            "legendFormat": "P99"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
        "yAxes": [
          {
            "label": "Latency (seconds)",
            "min": 0,
            "max": 0.1
          }
        ],
        "thresholds": [
          {"value": 0.01, "color": "green"},
          {"value": 0.05, "color": "yellow"},
          {"value": 0.1, "color": "red"}
        ]
      },
      {
        "id": 3,
        "title": "Inference Throughput",
        "type": "timeseries",
        "targets": [
          {
            "expr": "rate(carla_rl_inference_requests_total[5m])",
            "legendFormat": "Requests/sec"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
        "yAxes": [
          {
            "label": "Requests per second",
            "min": 0
          }
        ]
      },
      {
        "id": 4,
        "title": "Error Rate",
        "type": "timeseries",
        "targets": [
          {
            "expr": "rate(carla_rl_errors_total[5m])",
            "legendFormat": "Errors/sec"
          },
          {
            "expr": "rate(carla_rl_http_requests_total{status_code=~\"5..\"}[5m])",
            "legendFormat": "5xx Errors/sec"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
        "yAxes": [
          {
            "label": "Errors per second",
            "min": 0
          }
        ],
        "thresholds": [
          {"value": 0, "color": "green"},
          {"value": 0.1, "color": "yellow"},
          {"value": 1, "color": "red"}
        ]
      },
      {
        "id": 5,
        "title": "System Resources",
        "type": "timeseries",
        "targets": [
          {
            "expr": "carla_rl_cpu_usage_percent",
            "legendFormat": "CPU %"
          },
          {
            "expr": "carla_rl_memory_usage_percent",
            "legendFormat": "Memory %"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16},
        "yAxes": [
          {
            "label": "Percentage",
            "min": 0,
            "max": 100
          }
        ],
        "thresholds": [
          {"value": 80, "color": "yellow"},
          {"value": 90, "color": "red"}
        ]
      },
      {
        "id": 6,
        "title": "GPU Utilization",
        "type": "timeseries",
        "targets": [
          {
            "expr": "carla_rl_gpu_utilization_percent",
            "legendFormat": "GPU {{device_id}} %"
          },
          {
            "expr": "carla_rl_gpu_memory_usage_bytes / 1024 / 1024 / 1024",
            "legendFormat": "GPU {{device_id}} Memory (GB)"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16},
        "yAxes": [
          {
            "label": "Percentage / GB",
            "min": 0
          }
        ]
      },
      {
        "id": 7,
        "title": "Request Duration by Endpoint",
        "type": "timeseries",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(carla_rl_request_duration_seconds_bucket[5m])) by (endpoint)",
            "legendFormat": "{{endpoint}} P50"
          },
          {
            "expr": "histogram_quantile(0.95, rate(carla_rl_request_duration_seconds_bucket[5m])) by (endpoint)",
            "legendFormat": "{{endpoint}} P95"
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 24},
        "yAxes": [
          {
            "label": "Duration (seconds)",
            "min": 0
          }
        ]
      },
      {
        "id": 8,
        "title": "Batch Size Distribution",
        "type": "histogram",
        "targets": [
          {
            "expr": "rate(carla_rl_batch_size_bucket[5m])",
            "legendFormat": "Batch Size"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 32},
        "yAxes": [
          {
            "label": "Requests per second",
            "min": 0
          }
        ]
      },
      {
        "id": 9,
        "title": "Model Performance by Version",
        "type": "table",
        "targets": [
          {
            "expr": "carla_rl_model_loaded by (model_version, device)",
            "legendFormat": "Model Status"
          },
          {
            "expr": "histogram_quantile(0.50, rate(carla_rl_inference_duration_seconds_bucket[5m])) by (model_version)",
            "legendFormat": "P50 Latency"
          },
          {
            "expr": "rate(carla_rl_inference_requests_total[5m]) by (model_version)",
            "legendFormat": "Throughput"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 32},
        "transformations": [
          {
            "id": "organize",
            "options": {
              "excludeByName": {},
              "indexByName": {},
              "renameByName": {
                "Value": "Value",
                "model_version": "Version",
                "device": "Device"
              }
            }
          }
        ]
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "5s",
    "schemaVersion": 27,
    "version": 1,
    "links": []
  }
}
